!pip install selenium

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import requests
import os
from urllib.parse import urljoin


def download_image(img_url, folder, filename):
    """ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        response = requests.get(img_url, timeout=10)
        if response.status_code == 200:
            filepath = os.path.join(folder, filename)
            with open(filepath, 'wb') as f:
                f.write(response.content)
            print(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename}")
            return True
    except Exception as e:
        print(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ {filename}: {e}")
    return False


def crawl_musinsa_snaps(url, scroll_count=10):
    """ë¬´ì‹ ì‚¬ ìŠ¤ëƒ… í¬ë¡¤ë§ í•¨ìˆ˜ (5000ê°œ ì œí•œ ë¡œì§ ì¶”ê°€)"""

    # --- ì¶”ê°€ëœ ìƒìˆ˜ ---
    MAX_IMAGES = 5000  # í¬ë¡¤ë§ ìµœëŒ€ ì´ë¯¸ì§€ ê°œìˆ˜ ì œí•œ
    # ------------------

    # ì €ì¥ í´ë” ìƒì„±
    save_folder = "classic"
    if not os.path.exists(save_folder):
        os.makedirs(save_folder)

    # Chrome ì˜µì…˜ ì„¤ì •
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')  # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ (ë¸Œë¼ìš°ì € ì°½ ì•ˆ ë„ì›€)
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')

    # ë“œë¼ì´ë²„ ì‹œì‘
    driver = webdriver.Chrome(options=options)

    try:
        print(f"í˜ì´ì§€ ì ‘ì† ì¤‘: {url}")
        driver.get(url)

        # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
        time.sleep(3)

        # ì´ë¯¸ì§€ URLì„ ì €ì¥í•  set (ì¤‘ë³µ ë°©ì§€)
        image_urls = set()

        # ìŠ¤í¬ë¡¤ ë£¨í”„
        for i in range(scroll_count):
            print(f"\nìŠ¤í¬ë¡¤ {i + 1}/{scroll_count}")

            # í˜„ì¬ í˜ì´ì§€ì˜ ì´ë¯¸ì§€ ì°¾ê¸°
            img_elements = driver.find_elements(By.TAG_NAME, "img")

            for img in img_elements:
                try:
                    src = img.get_attribute('src')
                    # ì‹¤ì œ ìŠ¤ëƒ… ì´ë¯¸ì§€ë§Œ í•„í„°ë§ (ë¡œê³ ë‚˜ ì•„ì´ì½˜ ì œì™¸)
                    if src and ('snap' in src.lower() or 'image' in src.lower()):
                        if src.startswith('http'):
                            image_urls.add(src)
                except:
                    continue

            print(f"í˜„ì¬ê¹Œì§€ ë°œê²¬ëœ ì´ë¯¸ì§€: {len(image_urls)}ê°œ")

            # --- í•µì‹¬ ìˆ˜ì • ë¶€ë¶„: 5000ê°œ ì œí•œ ê²€ì‚¬ ë° ì¤‘ë‹¨ ---
            if len(image_urls) >= MAX_IMAGES:
                print(f"ğŸš¨ ë°œê²¬ëœ ì´ë¯¸ì§€ {len(image_urls)}ê°œê°€ ëª©í‘œ ê°œìˆ˜ {MAX_IMAGES}ê°œë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. í¬ë¡¤ë§ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                break
            # --------------------------------------------------

            # ìŠ¤í¬ë¡¤ ë‹¤ìš´
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)  # ìƒˆ ì´ë¯¸ì§€ ë¡œë“œ ëŒ€ê¸°


        print(f"\nì´ {len(image_urls)}ê°œì˜ ì´ë¯¸ì§€ ë°œê²¬")

        # ë‹¤ìš´ë¡œë“œí•  URL ë¦¬ìŠ¤íŠ¸ë¥¼ ìµœëŒ€ì¹˜ë¡œ ìŠ¬ë¼ì´ì‹± (5000ê°œ ì œí•œ)
        urls_to_download = list(image_urls)[:MAX_IMAGES]

        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        print("\nì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        downloaded = 0
        for idx, img_url in enumerate(urls_to_download, 1):
            filename = f"classic_{idx:04d}.jpg"
            if download_image(img_url, save_folder, filename):
                downloaded += 1

        print(f"\nâœ… ì™„ë£Œ! {downloaded}ê°œì˜ ì´ë¯¸ì§€ê°€ '{save_folder}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

    finally:
        driver.quit()


# ì‹¤í–‰
if __name__ == "__main__":
    # Classic(styles=9), Romantic(styles=12), ì„±ë³„í•„í„°(gf=A)ê°€ ëª¨ë‘ ì ìš©ëœ URL
    url = "https://www.musinsa.com/snap/main/recommend?styles=9&styles=12&gf=A"

    print(f"\n==========================================")
    print(f"[Classic & Romantic] í†µí•© í¬ë¡¤ë§ ì‹œì‘")
    print(f"URL: {url}")
    print(f"==========================================")

    # scroll_countëŠ” ì¶©ë¶„íˆ ë†’ì€ íšŸìˆ˜ë¥¼ ìœ ì§€í•˜ì—¬ 5000ê°œì— ë„ë‹¬í•  ë•Œê¹Œì§€ ìŠ¤í¬ë¡¤ ì‹œë„
    crawl_musinsa_snaps(url, scroll_count=3000)



#----------------------------------------------
import shutil
import os
from google.colab import files

# ì••ì¶•í•  í´ë” ì´ë¦„
folder_to_zip = "casual"
# ì••ì¶• íŒŒì¼ ì´ë¦„
zip_filename = f"{folder_to_zip}.zip"

# í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
if os.path.exists(folder_to_zip):
    # í´ë”ë¥¼ zip íŒŒì¼ë¡œ ì••ì¶•
    shutil.make_archive(folder_to_zip, 'zip', folder_to_zip)
    print(f"'{folder_to_zip}' í´ë”ê°€ '{zip_filename}'ìœ¼ë¡œ ì••ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # Colabì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ
    try:
        files.download(zip_filename)
        print(f"'{zip_filename}' íŒŒì¼ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
else:
    print(f"'{folder_to_zip}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
